{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investors' Sentiment & S&P500 : Merge Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Organisation:\n",
    "1. Data Collection - Subreddit\n",
    "2. Data Collection - Target \n",
    "3. **Merging Data (Current Notebook)**\n",
    "2. EDA and Preprocessing\n",
    "3. Model Tuning and Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "import string\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer, TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('ticks')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/final_df.csv\")\n",
    "target = pd.read_csv(\"data/sp500_diff.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['month'] = df['date'].dt.month\n",
    "df['year'] = df['date'].dt.year\n",
    "df['Date'] = df['date'].dt.date\n",
    "df.loc[:, 'year_and_month'] = df.loc[:, 'date'].apply(lambda x: '{}-{:02d}'.format(x.year, x.month))\n",
    "df.loc[:, 'week_of_year'] = df.loc[:, 'date'].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>is_self</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>n_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>author</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Date</th>\n",
       "      <th>year_and_month</th>\n",
       "      <th>week_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-03 18:02:40</td>\n",
       "      <td>Backtesting moving average crossover</td>\n",
       "      <td>Hello guys,  \\nI was trying to backtest a movi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/r/stocks/comments/ac4c0u/backtesting_moving_a...</td>\n",
       "      <td>bhandarimohit2029</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-03 20:07:03</td>\n",
       "      <td>r/Stocks Daily Discussion Thursday - Jan 03, 2019</td>\n",
       "      <td>These daily discussions run from Monday to Fri...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>/r/stocks/comments/ac54dw/rstocks_daily_discus...</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03 20:12:03</td>\n",
       "      <td>Can someone ELI5 what a cross signal Index is ...</td>\n",
       "      <td>I just finished Margin call on Netflix and was...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/r/stocks/comments/ac55o3/can_someone_eli5_wha...</td>\n",
       "      <td>tellmetheworld</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-03 20:54:22</td>\n",
       "      <td>Your AM Global Stocks Preview and a whole lot ...</td>\n",
       "      <td>\\n\\n### US Stocks\\n\\n* **US stocks index futu...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>/r/stocks/comments/ac5gf6/your_am_global_stock...</td>\n",
       "      <td>QuantalyticsResearch</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-03 21:01:23</td>\n",
       "      <td>Gld outperforms snp and Dow</td>\n",
       "      <td>Gld has outperformed the snp and Dow since 200...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>/r/stocks/comments/ac5ibv/gld_outperforms_snp_...</td>\n",
       "      <td>1anon2y3mous</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                              title  \\\n",
       "0 2019-01-03 18:02:40               Backtesting moving average crossover   \n",
       "1 2019-01-03 20:07:03  r/Stocks Daily Discussion Thursday - Jan 03, 2019   \n",
       "2 2019-01-03 20:12:03  Can someone ELI5 what a cross signal Index is ...   \n",
       "3 2019-01-03 20:54:22  Your AM Global Stocks Preview and a whole lot ...   \n",
       "4 2019-01-03 21:01:23                        Gld outperforms snp and Dow   \n",
       "\n",
       "                                            selftext  is_self  upvotes  \\\n",
       "0  Hello guys,  \\nI was trying to backtest a movi...      1.0      1.0   \n",
       "1  These daily discussions run from Monday to Fri...      1.0      1.0   \n",
       "2  I just finished Margin call on Netflix and was...      1.0      1.0   \n",
       "3   \\n\\n### US Stocks\\n\\n* **US stocks index futu...      1.0      1.0   \n",
       "4  Gld has outperformed the snp and Dow since 200...      1.0      1.0   \n",
       "\n",
       "   n_comments                                          permalink  \\\n",
       "0         0.0  /r/stocks/comments/ac4c0u/backtesting_moving_a...   \n",
       "1        12.0  /r/stocks/comments/ac54dw/rstocks_daily_discus...   \n",
       "2         0.0  /r/stocks/comments/ac55o3/can_someone_eli5_wha...   \n",
       "3        16.0  /r/stocks/comments/ac5gf6/your_am_global_stock...   \n",
       "4        30.0  /r/stocks/comments/ac5ibv/gld_outperforms_snp_...   \n",
       "\n",
       "                 author  month  year        Date year_and_month  week_of_year  \n",
       "0     bhandarimohit2029      1  2019  2019-01-03        2019-01             1  \n",
       "1         AutoModerator      1  2019  2019-01-03        2019-01             1  \n",
       "2        tellmetheworld      1  2019  2019-01-03        2019-01             1  \n",
       "3  QuantalyticsResearch      1  2019  2019-01-03        2019-01             1  \n",
       "4          1anon2y3mous      1  2019  2019-01-03        2019-01             1  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>is_self</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>n_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>author</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Date</th>\n",
       "      <th>year_and_month</th>\n",
       "      <th>week_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>508251</th>\n",
       "      <td>2020-12-31 23:46:51</td>\n",
       "      <td>Daily candles vs 8hr candles</td>\n",
       "      <td>Is the daily candle the result of 3 trading se...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/r/technicalanalysis/comments/kns8ps/daily_can...</td>\n",
       "      <td>engineertee</td>\n",
       "      <td>12</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2020-12</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508252</th>\n",
       "      <td>2021-01-01 02:41:41</td>\n",
       "      <td>Weekly Technical Forecast 31st December, 2020 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/r/technicalanalysis/comments/knvhz8/weekly_te...</td>\n",
       "      <td>ResearchSquared</td>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508253</th>\n",
       "      <td>2021-01-01 07:20:24</td>\n",
       "      <td>Quick Question - How do you decide which chart...</td>\n",
       "      <td>Guess the question is in the title...but do yo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>/r/technicalanalysis/comments/ko0dho/quick_que...</td>\n",
       "      <td>JustArran12345</td>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date                                              title  \\\n",
       "508251 2020-12-31 23:46:51                       Daily candles vs 8hr candles   \n",
       "508252 2021-01-01 02:41:41  Weekly Technical Forecast 31st December, 2020 ...   \n",
       "508253 2021-01-01 07:20:24  Quick Question - How do you decide which chart...   \n",
       "\n",
       "                                                 selftext  is_self  upvotes  \\\n",
       "508251  Is the daily candle the result of 3 trading se...      1.0      1.0   \n",
       "508252                                                NaN      0.0      1.0   \n",
       "508253  Guess the question is in the title...but do yo...      1.0      1.0   \n",
       "\n",
       "        n_comments                                          permalink  \\\n",
       "508251         2.0  /r/technicalanalysis/comments/kns8ps/daily_can...   \n",
       "508252         0.0  /r/technicalanalysis/comments/knvhz8/weekly_te...   \n",
       "508253         5.0  /r/technicalanalysis/comments/ko0dho/quick_que...   \n",
       "\n",
       "                 author  month  year        Date year_and_month  week_of_year  \n",
       "508251      engineertee     12  2020  2020-12-31        2020-12            53  \n",
       "508252  ResearchSquared      1  2021  2021-01-01        2021-01            53  \n",
       "508253   JustArran12345      1  2021  2021-01-01        2021-01            53  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 508254 entries, 0 to 508253\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count   Dtype         \n",
      "---  ------          --------------   -----         \n",
      " 0   date            508254 non-null  datetime64[ns]\n",
      " 1   title           508254 non-null  object        \n",
      " 2   selftext        349645 non-null  object        \n",
      " 3   is_self         508254 non-null  float64       \n",
      " 4   upvotes         508254 non-null  float64       \n",
      " 5   n_comments      508254 non-null  float64       \n",
      " 6   permalink       508254 non-null  object        \n",
      " 7   author          508254 non-null  object        \n",
      " 8   month           508254 non-null  int64         \n",
      " 9   year            508254 non-null  int64         \n",
      " 10  Date            508254 non-null  datetime64[ns]\n",
      " 11  year_and_month  508254 non-null  object        \n",
      " 12  week_of_year    508254 non-null  UInt32        \n",
      "dtypes: UInt32(1), datetime64[ns](2), float64(3), int64(2), object(5)\n",
      "memory usage: 49.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Diff</th>\n",
       "      <th>Percent_Change</th>\n",
       "      <th>Percent_Change_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2476.959961</td>\n",
       "      <td>2519.489990</td>\n",
       "      <td>2467.469971</td>\n",
       "      <td>2510.030029</td>\n",
       "      <td>2510.03</td>\n",
       "      <td>3733160000</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2491.919922</td>\n",
       "      <td>2493.139893</td>\n",
       "      <td>2443.959961</td>\n",
       "      <td>2447.889893</td>\n",
       "      <td>2447.89</td>\n",
       "      <td>3822860000</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>-62.140137</td>\n",
       "      <td>-0.025385</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2474.330078</td>\n",
       "      <td>2538.070068</td>\n",
       "      <td>2474.330078</td>\n",
       "      <td>2531.939941</td>\n",
       "      <td>2531.94</td>\n",
       "      <td>4213410000</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>84.050050</td>\n",
       "      <td>0.033196</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date         Open         High          Low        Close  Adj Close  \\\n",
       "0  2019-01-02  2476.959961  2519.489990  2467.469971  2510.030029    2510.03   \n",
       "1  2019-01-03  2491.919922  2493.139893  2443.959961  2447.889893    2447.89   \n",
       "2  2019-01-04  2474.330078  2538.070068  2474.330078  2531.939941    2531.94   \n",
       "\n",
       "       Volume  month  year       Diff  Percent_Change Percent_Change_Class  \n",
       "0  3733160000      1  2019        NaN             NaN                  NaN  \n",
       "1  3822860000      1  2019 -62.140137       -0.025385                 down  \n",
       "2  4213410000      1  2019  84.050050        0.033196                   up  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "target['Percent_Change_Class'] = target['Percent_Change_Class'].shift(-1)\n",
    "target.dropna(inplace = True)\n",
    "target['Date'] = pd.to_datetime(target['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 503 entries, 1 to 503\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   Date                  503 non-null    datetime64[ns]\n",
      " 1   Open                  503 non-null    float64       \n",
      " 2   High                  503 non-null    float64       \n",
      " 3   Low                   503 non-null    float64       \n",
      " 4   Close                 503 non-null    float64       \n",
      " 5   Adj Close             503 non-null    float64       \n",
      " 6   Volume                503 non-null    int64         \n",
      " 7   month                 503 non-null    int64         \n",
      " 8   year                  503 non-null    int64         \n",
      " 9   Diff                  503 non-null    float64       \n",
      " 10  Percent_Change        503 non-null    float64       \n",
      " 11  Percent_Change_Class  503 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(7), int64(3), object(1)\n",
      "memory usage: 51.1+ KB\n"
     ]
    }
   ],
   "source": [
    "target.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Dataset with Target Variable\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to dataset with target variable based on date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching the percentage_change_class based on date between the feature_df and target_df\n",
    "def match_dates_and_pull_y(features_df, target_df):\n",
    "    change = []\n",
    "\n",
    "    for i in features_df['Date']:\n",
    "        try:\n",
    "            if i in list(target_df['Date']):\n",
    "                change.append(target_df['Percent_Change_Class'].loc[target_df['Date']==i].values)\n",
    "            elif i not in list(target_df['Date']):\n",
    "                change.append('x')\n",
    "                pass\n",
    "        except Exception as e:\n",
    "            print('Error:', e)\n",
    "            \n",
    "    return pd.DataFrame(change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_combined_df = df.merge(change_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>is_self</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>n_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>author</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Date</th>\n",
       "      <th>year_and_month</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>percent_change_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-03 18:02:40</td>\n",
       "      <td>Backtesting moving average crossover</td>\n",
       "      <td>Hello guys,  \\nI was trying to backtest a movi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/r/stocks/comments/ac4c0u/backtesting_moving_a...</td>\n",
       "      <td>bhandarimohit2029</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>1</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-03 20:07:03</td>\n",
       "      <td>r/Stocks Daily Discussion Thursday - Jan 03, 2019</td>\n",
       "      <td>These daily discussions run from Monday to Fri...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>/r/stocks/comments/ac54dw/rstocks_daily_discus...</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>1</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03 20:12:03</td>\n",
       "      <td>Can someone ELI5 what a cross signal Index is ...</td>\n",
       "      <td>I just finished Margin call on Netflix and was...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/r/stocks/comments/ac55o3/can_someone_eli5_wha...</td>\n",
       "      <td>tellmetheworld</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>1</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-03 20:54:22</td>\n",
       "      <td>Your AM Global Stocks Preview and a whole lot ...</td>\n",
       "      <td>\\n\\n### US Stocks\\n\\n* **US stocks index futu...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>/r/stocks/comments/ac5gf6/your_am_global_stock...</td>\n",
       "      <td>QuantalyticsResearch</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>1</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-03 21:01:23</td>\n",
       "      <td>Gld outperforms snp and Dow</td>\n",
       "      <td>Gld has outperformed the snp and Dow since 200...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>/r/stocks/comments/ac5ibv/gld_outperforms_snp_...</td>\n",
       "      <td>1anon2y3mous</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>1</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                              title  \\\n",
       "0 2019-01-03 18:02:40               Backtesting moving average crossover   \n",
       "1 2019-01-03 20:07:03  r/Stocks Daily Discussion Thursday - Jan 03, 2019   \n",
       "2 2019-01-03 20:12:03  Can someone ELI5 what a cross signal Index is ...   \n",
       "3 2019-01-03 20:54:22  Your AM Global Stocks Preview and a whole lot ...   \n",
       "4 2019-01-03 21:01:23                        Gld outperforms snp and Dow   \n",
       "\n",
       "                                            selftext  is_self  upvotes  \\\n",
       "0  Hello guys,  \\nI was trying to backtest a movi...      1.0      1.0   \n",
       "1  These daily discussions run from Monday to Fri...      1.0      1.0   \n",
       "2  I just finished Margin call on Netflix and was...      1.0      1.0   \n",
       "3   \\n\\n### US Stocks\\n\\n* **US stocks index futu...      1.0      1.0   \n",
       "4  Gld has outperformed the snp and Dow since 200...      1.0      1.0   \n",
       "\n",
       "   n_comments                                          permalink  \\\n",
       "0         0.0  /r/stocks/comments/ac4c0u/backtesting_moving_a...   \n",
       "1        12.0  /r/stocks/comments/ac54dw/rstocks_daily_discus...   \n",
       "2         0.0  /r/stocks/comments/ac55o3/can_someone_eli5_wha...   \n",
       "3        16.0  /r/stocks/comments/ac5gf6/your_am_global_stock...   \n",
       "4        30.0  /r/stocks/comments/ac5ibv/gld_outperforms_snp_...   \n",
       "\n",
       "                 author  month  year       Date year_and_month  week_of_year  \\\n",
       "0     bhandarimohit2029      1  2019 2019-01-03        2019-01             1   \n",
       "1         AutoModerator      1  2019 2019-01-03        2019-01             1   \n",
       "2        tellmetheworld      1  2019 2019-01-03        2019-01             1   \n",
       "3  QuantalyticsResearch      1  2019 2019-01-03        2019-01             1   \n",
       "4          1anon2y3mous      1  2019 2019-01-03        2019-01             1   \n",
       "\n",
       "  percent_change_class  \n",
       "0                   up  \n",
       "1                   up  \n",
       "2                   up  \n",
       "3                   up  \n",
       "4                   up  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_combined_df.rename(columns={0:'percent_change_class'}, inplace=True)\n",
    "raw_combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['up', 'x', 'down'], dtype=object)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_combined_df['percent_change_class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119049, 14)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_x_only = combined_df[combined_df['percent_change_class'] == 'x']\n",
    "combined_df_x_only.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of days that post were being captured: 729\n",
      "The number of non-trading days: 227\n",
      "The number of trading days between 2019 & 2020: 502\n"
     ]
    }
   ],
   "source": [
    "# As the stock market is not open during the weekends and US holidays, the reddit posts that falls within the dates will not be able to determine the change in S&P500\n",
    "print(\"The total number of days that post were being captured: {}\".format(raw_combined_df['Date'].nunique()))\n",
    "print(\"The number of non-trading days: {}\".format(combined_df_x_only['Date'].nunique()))\n",
    "print(\"The number of trading days between 2019 & 2020: {}\".format((raw_combined_df['Date'].nunique() - combined_df_x_only['Date'].nunique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of post remaining after removing post from non-trading days: 0.77\n"
     ]
    }
   ],
   "source": [
    "# 77% of the orginal data is retained after removing non-trading days\n",
    "print(\"Percentage of post remaining after removing post from non-trading days: {}\".format(round(1 - (119049/x), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining dataset based on trading days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing relevant data (For title on daily basis)\n",
    "dailytitle_df = raw_combined_df[(combined_df['percent_change_class'] != 'x') & \\\n",
    "                            (combined_df['author'] != \"AutoModerator\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing relevant data (For combination of title and post for 2019)\n",
    "titlepost2019_df = raw_combined_df[(combined_df['percent_change_class'] != 'x') & \\\n",
    "                                   (combined_df['year'] == 2019) & \n",
    "                                   (combined_df['author'] != \"AutoModerator\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Title on daily basis\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_dict = {}\n",
    "\n",
    "for date in dailytitle_df['Date'].unique():\n",
    "    temp_df = dailytitle_df[dailytitle_df['Date'] == date]\n",
    "    title = temp_df['title']\n",
    "    title_dict[date] = \" \".join(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>Backtesting moving average crossover Can someo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>What’s your best performing stock today? How t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-07</th>\n",
       "      <td>Come Join Quantum Stock Trading! Help reach fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-08</th>\n",
       "      <td>Greenspan says stock market \"is still a bit to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-09</th>\n",
       "      <td>ONC, ONCY &amp;amp; ONC.WT What is everyone's opin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            0\n",
       "2019-01-03  Backtesting moving average crossover Can someo...\n",
       "2019-01-04  What’s your best performing stock today? How t...\n",
       "2019-01-07  Come Join Quantum Stock Trading! Help reach fi...\n",
       "2019-01-08  Greenspan says stock market \"is still a bit to...\n",
       "2019-01-09  ONC, ONCY &amp; ONC.WT What is everyone's opin..."
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailytitle_df = pd.DataFrame(title_dict, index=[0]).T\n",
    "dailytitle_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>combined_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>Backtesting moving average crossover Can someo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>What’s your best performing stock today? How t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>Come Join Quantum Stock Trading! Help reach fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>Greenspan says stock market \"is still a bit to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>ONC, ONCY &amp;amp; ONC.WT What is everyone's opin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                     combined_title\n",
       "0 2019-01-03  Backtesting moving average crossover Can someo...\n",
       "1 2019-01-04  What’s your best performing stock today? How t...\n",
       "2 2019-01-07  Come Join Quantum Stock Trading! Help reach fi...\n",
       "3 2019-01-08  Greenspan says stock market \"is still a bit to...\n",
       "4 2019-01-09  ONC, ONCY &amp; ONC.WT What is everyone's opin..."
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailytitle_df = dailytitle_df.reset_index()\n",
    "dailytitle_df.columns = ['Date', 'combined_title']\n",
    "dailytitle_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.276050\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "change_dailytitle_df = match_dates_and_pull_y(dailytitle_df, target)\n",
    "end = datetime.now()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>combined_title</th>\n",
       "      <th>percent_change_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>Backtesting moving average crossover Can someo...</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>What’s your best performing stock today? How t...</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>Come Join Quantum Stock Trading! Help reach fi...</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>Greenspan says stock market \"is still a bit to...</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>ONC, ONCY &amp;amp; ONC.WT What is everyone's opin...</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                     combined_title  \\\n",
       "0 2019-01-03  Backtesting moving average crossover Can someo...   \n",
       "1 2019-01-04  What’s your best performing stock today? How t...   \n",
       "2 2019-01-07  Come Join Quantum Stock Trading! Help reach fi...   \n",
       "3 2019-01-08  Greenspan says stock market \"is still a bit to...   \n",
       "4 2019-01-09  ONC, ONCY &amp; ONC.WT What is everyone's opin...   \n",
       "\n",
       "  percent_change_class  \n",
       "0                   up  \n",
       "1                   up  \n",
       "2                   up  \n",
       "3                   up  \n",
       "4                   up  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailytitle_df = dailytitle_df.merge(change_dailytitle_df, left_index=True, right_index=True)\n",
    "dailytitle_df.rename(columns = {0: 'percent_change_class'}, inplace = True)\n",
    "dailytitle_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "up      293\n",
      "down    209\n",
      "Name: percent_change_class, dtype: int64\n",
      "\n",
      "Total number of inputs: 502\n"
     ]
    }
   ],
   "source": [
    "print(dailytitle_df['percent_change_class'].value_counts())\n",
    "print()\n",
    "x = dailytitle_df['percent_change_class'].value_counts().sum()\n",
    "print('Total number of inputs: {}'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailytitle_df.to_csv(\"data/dailytitle_df_uncleaned\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_title(df_posts):\n",
    "    \n",
    "    # Filling in null values\n",
    "    df_posts.fillna(value = 'notext', inplace=True)\n",
    "\n",
    "    #Obtaining length of title and text\n",
    "    df = df_posts\n",
    "    df['title_len'] = [len(x) for x in df['combined_title'].str.split(' ')]\n",
    "    #df['text_len'] = [len(x) for x in df['selftext'].str.split(' ')]\n",
    "\n",
    "    # removing html within post\n",
    "    regex_html = r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)'\n",
    "    df['combined_title'].replace(regex=True,inplace=True, to_replace=regex_html,value=r'')\n",
    "    #df['selftext'].replace(regex=True,inplace=True, to_replace=regex_html,value=r'')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailytitle_df = preprocess_title(dailytitle_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove url and digits\n",
    "def review_to_words(raw_review):\n",
    "    \n",
    "    # 2. Remove non-letters.\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw_review)\n",
    "    letters_oneline = re.sub('([\\r\\n]+)',' ', letters_only) \n",
    "    letters = re.sub('([ ]{2,})',' ',letters_oneline)\n",
    "    \n",
    "    # 3. Convert to lower case, split into individual words.\n",
    "    words = letters.lower().split()\n",
    "    \n",
    "    # 4. Remove stopwords.\n",
    "    stops = set(stopwords.words('english'))\n",
    "    stops.update(['stocks', 'notext'])\n",
    "    data = [w for w in words if w not in stops]\n",
    "    \n",
    "    data = \" \".join(data)\n",
    "    \n",
    "    #5. Tokenizing\n",
    "    tokenizer = TweetTokenizer()\n",
    "    meaningful_words = tokenizer.tokenize(data)\n",
    "    \n",
    "    # 6.Lemmatizing.\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens_lem = [lemmatizer.lemmatize(word) for word in meaningful_words]\n",
    "    data = [w for w in tokens_lem if w not in stops]\n",
    "    \n",
    "    # 7. Join the words back into one string separated by space, and return the result.\n",
    "    return(\" \".join(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailytitle_df['title_cleaned'] = dailytitle_df['combined_title'].map(review_to_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>combined_title</th>\n",
       "      <th>percent_change_class</th>\n",
       "      <th>title_len</th>\n",
       "      <th>title_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>Backtesting moving average crossover Can someo...</td>\n",
       "      <td>up</td>\n",
       "      <td>108</td>\n",
       "      <td>backtesting moving average crossover someone e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>What’s your best performing stock today? How t...</td>\n",
       "      <td>up</td>\n",
       "      <td>503</td>\n",
       "      <td>best performing stock today explain option new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>Come Join Quantum Stock Trading! Help reach fi...</td>\n",
       "      <td>up</td>\n",
       "      <td>209</td>\n",
       "      <td>come join quantum stock trading help reach fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>Greenspan says stock market \"is still a bit to...</td>\n",
       "      <td>up</td>\n",
       "      <td>541</td>\n",
       "      <td>greenspan say stock market still bit high appl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>ONC, ONCY &amp;amp; ONC.WT What is everyone's opin...</td>\n",
       "      <td>up</td>\n",
       "      <td>472</td>\n",
       "      <td>onc oncy amp onc wt everyone opinion company d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                     combined_title  \\\n",
       "0 2019-01-03  Backtesting moving average crossover Can someo...   \n",
       "1 2019-01-04  What’s your best performing stock today? How t...   \n",
       "2 2019-01-07  Come Join Quantum Stock Trading! Help reach fi...   \n",
       "3 2019-01-08  Greenspan says stock market \"is still a bit to...   \n",
       "4 2019-01-09  ONC, ONCY &amp; ONC.WT What is everyone's opin...   \n",
       "\n",
       "  percent_change_class  title_len  \\\n",
       "0                   up        108   \n",
       "1                   up        503   \n",
       "2                   up        209   \n",
       "3                   up        541   \n",
       "4                   up        472   \n",
       "\n",
       "                                       title_cleaned  \n",
       "0  backtesting moving average crossover someone e...  \n",
       "1  best performing stock today explain option new...  \n",
       "2  come join quantum stock trading help reach fin...  \n",
       "3  greenspan say stock market still bit high appl...  \n",
       "4  onc oncy amp onc wt everyone opinion company d...  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailytitle_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                    0\n",
       "combined_title          0\n",
       "percent_change_class    0\n",
       "title_len               0\n",
       "title_cleaned           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailytitle_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailytitle_df.to_csv(\"data/project_df_dailytitle_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Title + Post for 2019\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>is_self</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>n_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>author</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Date</th>\n",
       "      <th>year_and_month</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>percent_change_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-03 18:02:40</td>\n",
       "      <td>Backtesting moving average crossover</td>\n",
       "      <td>Hello guys,  \\nI was trying to backtest a movi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/r/stocks/comments/ac4c0u/backtesting_moving_a...</td>\n",
       "      <td>bhandarimohit2029</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>1</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03 20:12:03</td>\n",
       "      <td>Can someone ELI5 what a cross signal Index is ...</td>\n",
       "      <td>I just finished Margin call on Netflix and was...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/r/stocks/comments/ac55o3/can_someone_eli5_wha...</td>\n",
       "      <td>tellmetheworld</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>1</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-03 20:54:22</td>\n",
       "      <td>Your AM Global Stocks Preview and a whole lot ...</td>\n",
       "      <td>\\n\\n### US Stocks\\n\\n* **US stocks index futu...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>/r/stocks/comments/ac5gf6/your_am_global_stock...</td>\n",
       "      <td>QuantalyticsResearch</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>1</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-03 21:01:23</td>\n",
       "      <td>Gld outperforms snp and Dow</td>\n",
       "      <td>Gld has outperformed the snp and Dow since 200...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>/r/stocks/comments/ac5ibv/gld_outperforms_snp_...</td>\n",
       "      <td>1anon2y3mous</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>1</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-01-03 21:17:40</td>\n",
       "      <td>Alternative to Yahoo Finance</td>\n",
       "      <td>Hi there, i switched from Android to iOS.\\n\\nI...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>/r/stocks/comments/ac5mqv/alternative_to_yahoo...</td>\n",
       "      <td>h0ly88</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>1</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                              title  \\\n",
       "0 2019-01-03 18:02:40               Backtesting moving average crossover   \n",
       "2 2019-01-03 20:12:03  Can someone ELI5 what a cross signal Index is ...   \n",
       "3 2019-01-03 20:54:22  Your AM Global Stocks Preview and a whole lot ...   \n",
       "4 2019-01-03 21:01:23                        Gld outperforms snp and Dow   \n",
       "5 2019-01-03 21:17:40                       Alternative to Yahoo Finance   \n",
       "\n",
       "                                            selftext  is_self  upvotes  \\\n",
       "0  Hello guys,  \\nI was trying to backtest a movi...      1.0      1.0   \n",
       "2  I just finished Margin call on Netflix and was...      1.0      1.0   \n",
       "3   \\n\\n### US Stocks\\n\\n* **US stocks index futu...      1.0      1.0   \n",
       "4  Gld has outperformed the snp and Dow since 200...      1.0      1.0   \n",
       "5  Hi there, i switched from Android to iOS.\\n\\nI...      1.0      1.0   \n",
       "\n",
       "   n_comments                                          permalink  \\\n",
       "0         0.0  /r/stocks/comments/ac4c0u/backtesting_moving_a...   \n",
       "2         0.0  /r/stocks/comments/ac55o3/can_someone_eli5_wha...   \n",
       "3        16.0  /r/stocks/comments/ac5gf6/your_am_global_stock...   \n",
       "4        30.0  /r/stocks/comments/ac5ibv/gld_outperforms_snp_...   \n",
       "5        10.0  /r/stocks/comments/ac5mqv/alternative_to_yahoo...   \n",
       "\n",
       "                 author  month  year       Date year_and_month  week_of_year  \\\n",
       "0     bhandarimohit2029      1  2019 2019-01-03        2019-01             1   \n",
       "2        tellmetheworld      1  2019 2019-01-03        2019-01             1   \n",
       "3  QuantalyticsResearch      1  2019 2019-01-03        2019-01             1   \n",
       "4          1anon2y3mous      1  2019 2019-01-03        2019-01             1   \n",
       "5                h0ly88      1  2019 2019-01-03        2019-01             1   \n",
       "\n",
       "  percent_change_class  \n",
       "0                   up  \n",
       "2                   up  \n",
       "3                   up  \n",
       "4                   up  \n",
       "5                   up  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titlepost2019_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 67482 entries, 0 to 507461\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   date                  67482 non-null  datetime64[ns]\n",
      " 1   title                 67482 non-null  object        \n",
      " 2   selftext              46810 non-null  object        \n",
      " 3   is_self               67482 non-null  float64       \n",
      " 4   upvotes               67482 non-null  float64       \n",
      " 5   n_comments            67482 non-null  float64       \n",
      " 6   permalink             67482 non-null  object        \n",
      " 7   author                67482 non-null  object        \n",
      " 8   month                 67482 non-null  int64         \n",
      " 9   year                  67482 non-null  int64         \n",
      " 10  Date                  67482 non-null  datetime64[ns]\n",
      " 11  year_and_month        67482 non-null  object        \n",
      " 12  week_of_year          67482 non-null  UInt32        \n",
      " 13  percent_change_class  67482 non-null  object        \n",
      "dtypes: UInt32(1), datetime64[ns](2), float64(3), int64(2), object(6)\n",
      "memory usage: 7.5+ MB\n"
     ]
    }
   ],
   "source": [
    "titlepost2019_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df_posts):\n",
    "    \n",
    "    # Filling in null values\n",
    "    df_posts.fillna(value = 'notext', inplace=True)\n",
    "\n",
    "    #Obtaining length of title and text\n",
    "    df = df_posts\n",
    "    df['title_len'] = [len(x) for x in df['title'].str.split(' ')]\n",
    "    df['text_len'] = [len(x) for x in df['selftext'].str.split(' ')]\n",
    "\n",
    "    # removing html within post\n",
    "    regex_html = r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)'\n",
    "    df['title'].replace(regex=True,inplace=True, to_replace=regex_html,value=r'')\n",
    "    df['selftext'].replace(regex=True,inplace=True, to_replace=regex_html,value=r'')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "titlepost2019_df = preprocess(titlepost2019_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove url and digits\n",
    "def review_to_words(raw_review):\n",
    "    \n",
    "    # 2. Remove non-letters.\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw_review)\n",
    "    letters_oneline = re.sub('([\\r\\n]+)',' ', letters_only) \n",
    "    letters = re.sub('([ ]{2,})',' ',letters_oneline)\n",
    "    \n",
    "    # 3. Convert to lower case, split into individual words.\n",
    "    words = letters.lower().split()\n",
    "    \n",
    "    # 4. Remove stopwords.\n",
    "    stops = set(stopwords.words('english'))\n",
    "    stops.update(['notext', 'sma', 'year', 'month', 'day', 'gt', 'click', 'long', 'term', 'stock', 'market', 'way', \\\n",
    "                  'global', 'idea', 'ty', 'amp', 'ta', 'cap', 'st', 'live', 'pre', 'company', 'like', 'time', \\\n",
    "                  'price', 'earnings', 'removed', 'option', 'trading', 'trade', 'today', 'want', 'sell', 'thought', \\\n",
    "                  'investing', 'invest', 'money', 'good', 'new', 'week', 'think', 'going', 'account', 'option', \\\n",
    "                  'stocks', 'know', 'make', 'shares', 'spy', 'million', 'buying', 'fund', 'revenue', ' short', \\\n",
    "                  'investement', 'looking', 'buy', 'investment', 'people', 'share', 'china', 'guy', 'right', 'curr', \\\n",
    "                  'key', 'avg', 'fn', 'tn', 'tp', 'bb', 'rsi', 'hang', 'seng', 'chart', 'sch', 'stofu', 'yr', 'feel', \\\n",
    "                  'morning', 'coo', 'elon', 'mask', 'wall', 'street', 'stoxx', 'usd', 'calendar', 'kong', 'united', \\\n",
    "                  'macd', 'quote', 'thanks', 'advance', 'information', 'technology', 'tl', 'dr', 'dae', 'growth', 'news', \\\n",
    "                  'investor', 'dividend', 'billion', 'roth', 'ira', 'etf', 'question', 'index', 'hong', 'state', 'fy', 'fp',\\\n",
    "                  'rate', 'cut', 'goldman', 'sachs', 'economic', 'appreciated', 'reached', 'sector', 'dt', 'tgt', 'warren', \\\n",
    "                  'real', 'estate', 'basis', 'say', 'discretionary', 'yahoo', 'finance', 'morgan', 'stanley', 'south', \\\n",
    "                  'korea', 'oversold', 'according', 'com', 'briefing', 'president', 'captial', 'student', 'buffet', \\\n",
    "                  'td', 'ameritrade', 'yield', 'charles', 'schwab', 'quarter', 'reported', 'high', 'short', 'portfolio', \\\n",
    "                  'robinhood', 'donald', 'trump', 'bln', 'federal', 'reserve', 'bank', 'currently', 'robin', 'hood',  \\\n",
    "                  'cash', 'changed', 'webp', 'dow', 'jones', 'dir', 'wti', 'capital', 'large', 'hit', 'beat', 'map', \\\n",
    "                  'credit', 'card', 'expected', 'neutral', 'rated', 'exp', 'dax', 'glf', 'finished', 'cac', 'euro', \\\n",
    "                  'format', 'png', 'auto', 'nikkei', 'yesterday', 'technical', 'shanghai','need', 'said', 'thing', 'work', \\\n",
    "                  'balance', 'sheet', 'estimate', 'interactive', 'broker', 'overbought', 'low', 'bond', 'future', 'risk', \\\n",
    "                  'position', 'advice', 'little', 'strategy', 'read', 'higher', 'apple', 'symbol', 'ago', 'tesla', 'pay', \\\n",
    "                  'holding', 'average', 'cnbc', 'margin', 'th', 'product', 'small', 'data', 'open', 'total', 'app', 'world',\\\n",
    "                  'profit', 'look', 'start', 'gain', ' future', 'lot', 'loss', 'let', 'free', 'post', \\\n",
    "                  'big', 'business', 'return', 'sale', 'tax', 'shit', 'financial', 'report', 'best', 'bought', \\\n",
    "                  'ratio', 'closing', 'closed', 'value', 'really', 'help', 'hold', 'come', 'end', 'got', 'play', \\\n",
    "                  'service', 'dollar', 'better', 'worth', 'trying', 'recession', 'thinking', 'gold', 'getting', 'debt', \\\n",
    "                  'mini', 'nasdaq', 'oz', 'link', 'afternoon', 'ipo', 'bbl', 'insider', 'lyft', 'ba', 'yes', 'health', 'care', \\\n",
    "                  'profit', 'use', 'point', 'deal', 'cost', 'le', ' selling', 'recently', 'understand', \\\n",
    "                  'japanese', 'release', 'nd', 'mean', 'number', 'tomorrow', 'wondering', 'actually', 'drop', 'platform',\\\n",
    "                  'current', 'selling', 'plan', 'sure', 'great', 'world', 'industry', 'fed', 'using', 'income', 'potential',\\\n",
    "                  'signal', 'result', 'txn', 'io', 'past', 'close', 'making', 'order', 'bad', 'fuck', 'analyst', 'opinion',\\\n",
    "                  'fee', 'based', 'pretty', 'started', 'dd', 'bit', 'monday', 'tuesday', 'wednesday', ' thursday', 'friday', \\\n",
    "                  'sold', 'perf', 'economy', 'job', 'lower', 'coming', 'research', 'hi', 'fucking', 'chinese', 'google', 'reason', \\\n",
    "                  'old'])\n",
    "    \n",
    "    data = [w for w in words if w not in stops]\n",
    "    \n",
    "    data = \" \".join(data)\n",
    "    \n",
    "    #5. Tokenizing\n",
    "    tokenizer = TweetTokenizer()\n",
    "    meaningful_words = tokenizer.tokenize(data)\n",
    "    \n",
    "    # 6.Lemmatizing.\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens_lem = [lemmatizer.lemmatize(word) for word in meaningful_words]\n",
    "    data = [w for w in tokens_lem if w not in stops]\n",
    "    \n",
    "    # 7. Join the words back into one string separated by space, and return the result.\n",
    "    return(\" \".join(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "titlepost2019_df['first_title_cleaned'] = titlepost2019_df['title'].map(review_to_words)\n",
    "titlepost2019_df['first_selftext_cleaned'] = titlepost2019_df['selftext'].map(review_to_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the function by updating the stopwords to run again. \n",
    "titlepost2019_df['final_title_cleaned'] = titlepost2019_df['title'].map(review_to_words)\n",
    "titlepost2019_df['final_selftext_cleaned'] = titlepost2019_df['selftext'].map(review_to_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinging Title and Post into a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "titlepost2019_df['fresh_meat'] = titlepost2019_df['first_title_cleaned'] + \" \" + titlepost2019_df['first_selftext_cleaned']\n",
    "titlepost2019_df['lean_meat'] = titlepost2019_df['final_title_cleaned'] + \" \" + titlepost2019_df['final_selftext_cleaned']\n",
    "titlepost2019_df['lean_meat_len'] = [len(x) for x in titlepost2019_df['lean_meat'].str.split(' ')]\n",
    "titlepost2019_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>is_self</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>n_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>author</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Date</th>\n",
       "      <th>year_and_month</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>percent_change_class</th>\n",
       "      <th>title_len</th>\n",
       "      <th>text_len</th>\n",
       "      <th>first_title_cleaned</th>\n",
       "      <th>first_selftext_cleaned</th>\n",
       "      <th>final_title_cleaned</th>\n",
       "      <th>final_selftext_cleaned</th>\n",
       "      <th>fresh_meat</th>\n",
       "      <th>lean_meat</th>\n",
       "      <th>lean_meat_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-03 18:02:40</td>\n",
       "      <td>Backtesting moving average crossover</td>\n",
       "      <td>Hello guys,  \\nI was trying to backtest a movi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/r/stocks/comments/ac4c0u/backtesting_moving_a...</td>\n",
       "      <td>bhandarimohit2029</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>1</td>\n",
       "      <td>up</td>\n",
       "      <td>4</td>\n",
       "      <td>212</td>\n",
       "      <td>backtesting moving average crossover</td>\n",
       "      <td>hello guy trying backtest moving average cross...</td>\n",
       "      <td>backtesting moving crossover</td>\n",
       "      <td>hello backtest moving crossover indian found i...</td>\n",
       "      <td>backtesting moving average crossover hello guy...</td>\n",
       "      <td>backtesting moving crossover hello backtest mo...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03 20:12:03</td>\n",
       "      <td>Can someone ELI5 what a cross signal Index is ...</td>\n",
       "      <td>I just finished Margin call on Netflix and was...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/r/stocks/comments/ac55o3/can_someone_eli5_wha...</td>\n",
       "      <td>tellmetheworld</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>1</td>\n",
       "      <td>up</td>\n",
       "      <td>16</td>\n",
       "      <td>59</td>\n",
       "      <td>someone eli cross signal index used trading</td>\n",
       "      <td>finished margin call netflix intrigued using i...</td>\n",
       "      <td>someone eli cross used</td>\n",
       "      <td>call netflix intrigued indicator sort proof sk...</td>\n",
       "      <td>someone eli cross signal index used trading fi...</td>\n",
       "      <td>someone eli cross used call netflix intrigued ...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-03 20:54:22</td>\n",
       "      <td>Your AM Global Stocks Preview and a whole lot ...</td>\n",
       "      <td>\\n\\n### US Stocks\\n\\n* **US stocks index futu...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>/r/stocks/comments/ac5gf6/your_am_global_stock...</td>\n",
       "      <td>QuantalyticsResearch</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>1</td>\n",
       "      <td>up</td>\n",
       "      <td>24</td>\n",
       "      <td>1033</td>\n",
       "      <td>global stock preview whole lot news need read ...</td>\n",
       "      <td>u stock u stock index future dropping sharply ...</td>\n",
       "      <td>preview whole negative guidance aapl spook</td>\n",
       "      <td>u u dropping sharply front p negative guidance...</td>\n",
       "      <td>global stock preview whole lot news need read ...</td>\n",
       "      <td>preview whole negative guidance aapl spook u u...</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-03 21:01:23</td>\n",
       "      <td>Gld outperforms snp and Dow</td>\n",
       "      <td>Gld has outperformed the snp and Dow since 200...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>/r/stocks/comments/ac5ibv/gld_outperforms_snp_...</td>\n",
       "      <td>1anon2y3mous</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>1</td>\n",
       "      <td>up</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>gld outperforms snp dow</td>\n",
       "      <td>gld outperformed snp dow since gold bad rap in...</td>\n",
       "      <td>gld outperforms snp</td>\n",
       "      <td>gld outperformed snp since rap</td>\n",
       "      <td>gld outperforms snp dow gld outperformed snp d...</td>\n",
       "      <td>gld outperforms snp gld outperformed snp since...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-01-03 21:17:40</td>\n",
       "      <td>Alternative to Yahoo Finance</td>\n",
       "      <td>Hi there, i switched from Android to iOS.\\n\\nI...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>/r/stocks/comments/ac5mqv/alternative_to_yahoo...</td>\n",
       "      <td>h0ly88</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>1</td>\n",
       "      <td>up</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>alternative yahoo finance</td>\n",
       "      <td>hi switched android io always used mystocks ap...</td>\n",
       "      <td>alternative</td>\n",
       "      <td>switched android always used mystocks android ...</td>\n",
       "      <td>alternative yahoo finance hi switched android ...</td>\n",
       "      <td>alternative switched android always used mysto...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                              title  \\\n",
       "0 2019-01-03 18:02:40               Backtesting moving average crossover   \n",
       "2 2019-01-03 20:12:03  Can someone ELI5 what a cross signal Index is ...   \n",
       "3 2019-01-03 20:54:22  Your AM Global Stocks Preview and a whole lot ...   \n",
       "4 2019-01-03 21:01:23                        Gld outperforms snp and Dow   \n",
       "5 2019-01-03 21:17:40                       Alternative to Yahoo Finance   \n",
       "\n",
       "                                            selftext  is_self  upvotes  \\\n",
       "0  Hello guys,  \\nI was trying to backtest a movi...      1.0      1.0   \n",
       "2  I just finished Margin call on Netflix and was...      1.0      1.0   \n",
       "3   \\n\\n### US Stocks\\n\\n* **US stocks index futu...      1.0      1.0   \n",
       "4  Gld has outperformed the snp and Dow since 200...      1.0      1.0   \n",
       "5  Hi there, i switched from Android to iOS.\\n\\nI...      1.0      1.0   \n",
       "\n",
       "   n_comments                                          permalink  \\\n",
       "0         0.0  /r/stocks/comments/ac4c0u/backtesting_moving_a...   \n",
       "2         0.0  /r/stocks/comments/ac55o3/can_someone_eli5_wha...   \n",
       "3        16.0  /r/stocks/comments/ac5gf6/your_am_global_stock...   \n",
       "4        30.0  /r/stocks/comments/ac5ibv/gld_outperforms_snp_...   \n",
       "5        10.0  /r/stocks/comments/ac5mqv/alternative_to_yahoo...   \n",
       "\n",
       "                 author  month  year       Date year_and_month  week_of_year  \\\n",
       "0     bhandarimohit2029      1  2019 2019-01-03        2019-01             1   \n",
       "2        tellmetheworld      1  2019 2019-01-03        2019-01             1   \n",
       "3  QuantalyticsResearch      1  2019 2019-01-03        2019-01             1   \n",
       "4          1anon2y3mous      1  2019 2019-01-03        2019-01             1   \n",
       "5                h0ly88      1  2019 2019-01-03        2019-01             1   \n",
       "\n",
       "  percent_change_class  title_len  text_len  \\\n",
       "0                   up          4       212   \n",
       "2                   up         16        59   \n",
       "3                   up         24      1033   \n",
       "4                   up          5        20   \n",
       "5                   up          4        65   \n",
       "\n",
       "                                 first_title_cleaned  \\\n",
       "0               backtesting moving average crossover   \n",
       "2        someone eli cross signal index used trading   \n",
       "3  global stock preview whole lot news need read ...   \n",
       "4                            gld outperforms snp dow   \n",
       "5                          alternative yahoo finance   \n",
       "\n",
       "                              first_selftext_cleaned  \\\n",
       "0  hello guy trying backtest moving average cross...   \n",
       "2  finished margin call netflix intrigued using i...   \n",
       "3  u stock u stock index future dropping sharply ...   \n",
       "4  gld outperformed snp dow since gold bad rap in...   \n",
       "5  hi switched android io always used mystocks ap...   \n",
       "\n",
       "                          final_title_cleaned  \\\n",
       "0                backtesting moving crossover   \n",
       "2                      someone eli cross used   \n",
       "3  preview whole negative guidance aapl spook   \n",
       "4                         gld outperforms snp   \n",
       "5                                 alternative   \n",
       "\n",
       "                              final_selftext_cleaned  \\\n",
       "0  hello backtest moving crossover indian found i...   \n",
       "2  call netflix intrigued indicator sort proof sk...   \n",
       "3  u u dropping sharply front p negative guidance...   \n",
       "4                     gld outperformed snp since rap   \n",
       "5  switched android always used mystocks android ...   \n",
       "\n",
       "                                          fresh_meat  \\\n",
       "0  backtesting moving average crossover hello guy...   \n",
       "2  someone eli cross signal index used trading fi...   \n",
       "3  global stock preview whole lot news need read ...   \n",
       "4  gld outperforms snp dow gld outperformed snp d...   \n",
       "5  alternative yahoo finance hi switched android ...   \n",
       "\n",
       "                                           lean_meat  lean_meat_len  \n",
       "0  backtesting moving crossover hello backtest mo...             85  \n",
       "2  someone eli cross used call netflix intrigued ...             24  \n",
       "3  preview whole negative guidance aapl spook u u...            327  \n",
       "4  gld outperforms snp gld outperformed snp since...              8  \n",
       "5  alternative switched android always used mysto...             23  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titlepost2019_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "up      39987\n",
       "down    27495\n",
       "Name: percent_change_class, dtype: int64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titlepost2019_df.percent_change_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 67482 entries, 0 to 507461\n",
      "Data columns (total 23 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   date                    67482 non-null  datetime64[ns]\n",
      " 1   title                   67482 non-null  object        \n",
      " 2   selftext                67482 non-null  object        \n",
      " 3   is_self                 67482 non-null  float64       \n",
      " 4   upvotes                 67482 non-null  float64       \n",
      " 5   n_comments              67482 non-null  float64       \n",
      " 6   permalink               67482 non-null  object        \n",
      " 7   author                  67482 non-null  object        \n",
      " 8   month                   67482 non-null  int64         \n",
      " 9   year                    67482 non-null  int64         \n",
      " 10  Date                    67482 non-null  datetime64[ns]\n",
      " 11  year_and_month          67482 non-null  object        \n",
      " 12  week_of_year            67482 non-null  UInt32        \n",
      " 13  percent_change_class    67482 non-null  object        \n",
      " 14  title_len               67482 non-null  int64         \n",
      " 15  text_len                67482 non-null  int64         \n",
      " 16  first_title_cleaned     67482 non-null  object        \n",
      " 17  first_selftext_cleaned  67482 non-null  object        \n",
      " 18  final_title_cleaned     67482 non-null  object        \n",
      " 19  final_selftext_cleaned  67482 non-null  object        \n",
      " 20  fresh_meat              67482 non-null  object        \n",
      " 21  lean_meat               67482 non-null  object        \n",
      " 22  lean_meat_len           67482 non-null  int64         \n",
      "dtypes: UInt32(1), datetime64[ns](2), float64(3), int64(5), object(12)\n",
      "memory usage: 12.2+ MB\n"
     ]
    }
   ],
   "source": [
    "titlepost2019_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titlepost2019_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "titlepost2019_df.to_csv(\"data/project_titlepost2019_df_cleaned.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
